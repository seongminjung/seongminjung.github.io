<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Lecture 2 | Image Classification</title>
    <meta name="description" content="Seongmin Jung's personal website" />
    <meta name="keywords" content="Seongmin Jung, Robotics" />
    <meta name="author" content="Seongmin Jung" />
    <meta name="language" content="English" />
    <link rel="shortcut icon" href="/favicon.png" />

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-LL44K1WZ0G"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() {
        dataLayer.push(arguments);
      }
      gtag("js", new Date());
      gtag("config", "G-LL44K1WZ0G");
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
      });
    </script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML" async></script>

    <!-- Load an icon library to show a hamburger menu (bars) on small screens -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" />
    <!-- import css -->
    <link rel="stylesheet" href="/css/index.css" />
    <!-- import js -->
    <script src="/js/script.js" defer></script>
  </head>

  <body>
    <header>
      <img class="cover" src="/asset/cover.jpg" alt="Seongmin Jung" />
      <h1 class="title"><a href="/index.html">Seongmin Jung</a></h1>
      <nav class="nav">
        <a href="/index.html">Home</a>
        <a href="/projects.html">Projects</a>
        <a href="/study.html" class="bold">Study</a>
        <a href="/blog.html">Blog</a>
        <i id="nav-toggle" class="nav-toggle fa fa-bars" onclick="toggleNav()"></i>
      </nav>
    </header>

    <div id="nav-modal-bg" onclick="toggleNav()"></div>
    <nav id="nav-modal">
      <a href="/index.html">Home</a>
      <a href="/projects.html">Projects</a>
      <a href="/study.html" class="bold">Study</a>
      <a href="/blog.html">Blog</a>
    </nav>

    <main>
      <div class="container">
        <section id="post">
          <a id="series-tag" href="/study/deep_learning_for_computer_vision.html"
            ><i class="fa fa-book"></i> Deep Learning for Computer Vision</a
          >
          <h1>Lecture 2 | Image Classification</h1>
          <p class="date">Posted on <time datetime="2024-03-26">March 26, 2024</time></p>
          <div class="post-body">
            <h2>Image Classification</h2>
            <p>
              컴퓨터 비전의 가장 기초적인 문제로 이미지 분류가 있다. 이미지 분류는 이미지를 입력으로 받아 그 이미지가
              개, 고양이, 자동차 등 어떤 클래스에 속하는지 분류하는 문제이다. 그렇다면 어떤 이미지가 특정 클래스에
              속하는지 컴퓨터가 어떻게 판단할 수 있을까?
            </p>
            <p>
              가장 직관적이고 단순한 방법은 단순히 픽셀 밝기 값들의 차이를 구해서 차이가 가장 작은 이미지의 클래스를
              따라가는 것이다. 그림으로 표현하면 다음과 같다.
            </p>
            <img src="/study/deep_learning_for_computer_vision/lecture_2/img1.png" alt="Pixel value subtraction" />
            <p>위 그림처럼 차의 절댓값을 모두 합한 것을 L1 distance라 한다. L1 norm과 같은 개념.</p>
            <p>이와 유사하게 L2 distance는 차의 제곱을 모두 합한 뒤 제곱근을 씌운 것이다. L2 norm과 같은 개념.</p>
            <img
              class="half"
              src="/study/deep_learning_for_computer_vision/lecture_2/img2.png"
              alt="L1 distance and L2 distance"
            />
            <p>
              세상의 모든 이미지를 한 군데에 모아 놓고, 위 식을 이용해서 주어진 이미지와 픽셀값이 가장 유사한 이미지를
              찾으면 그 두 이미지에는 같은 물체가 있지 않을까?
            </p>

            <h2>Nearest Neighbor</h2>
            <p>
              이 단순한 발상을 알고리즘으로 옮긴 것이 바로 Nearest Neighbor다. 여러 이미지들 중 주어진 이미지와 가장
              유사한 이미지를 찾고, 그 이미지와 같은 클래스를 부여하는 것이다. 이 알고리즘을 시각화해 보면 다음과 같다.
            </p>
            <img
              class="half"
              src="/study/deep_learning_for_computer_vision/lecture_2/img3.png"
              alt="Nearest Neighbor visualization"
            />
            <p>
              위 사진은 2차원 평면 상 점들을 이미지라고 가정하고 decision boundary를 그린 것이다. 각 색깔은 서로 다른
              클래스를 나타낸다. 이 상태에서 새로운 점이 들어온다면, 그 점과 가장 거리가 가까운 점과 같은 색을 가질
              것이다. 그렇기 때문에 사진 가운데에 outlier로 보이는 노란색 점이 초록색 점에 둘러싸여 있지만, 그 점
              주변에서는 새로운 점이 노란색으로 분류될 것이다.
            </p>

            <h2>k-Nearest Neighbors (kNN)</h2>
            <p>
              이를 보완하기 위해 가장 가까운 점을 여러 개 선택하여 최다 득표를 받은 클래스를 선택할 수 있다. 여기서 k는
              비교할 점(이미지)의 개수를 뜻하는데, k가 1이면 가장 유사한 이미지 하나의 클래스를 따라간다는 뜻이고, 3이면
              가장 유사한 3개 이미지를 뽑아 셋 중 가장 많은 수가 나온 클래스를 따라가는 식이다. 아래 사진을 통해 k가
              증가할수록 가운데 노란색 점과 같은 outlier에 강인해지는 모습을 확인할 수 있다.
            </p>
            <img src="/study/deep_learning_for_computer_vision/lecture_2/img4.png" alt="kNN visualization" />
            <p>아래 웹사이트를 통해 여러 파라미터를 바꾸어 보며 kNN 알고리즘을 시각적으로 확인할 수 있다.</p>
            <p>
              <a href="http://vision.stanford.edu/teaching/cs231n-demos/knn/"
                >http://vision.stanford.edu/teaching/cs231n-demos/knn/</a
              >
            </p>
            <p>
              이 알고리즘은 단순한 만큼 치명적인 단점이 있다. Training에는 아무런 연산이 필요하지 않은 반면 prediction에
              엄청난 연산이 소요된다는 점이다. Training은 사실상 아무런 연산 과정 없이 주어진 데이터를 그대로 저장하기만
              하면 되므로 O(1)이다. 반면 prediction에서는 모든 training 데이터와의 distance를 계산해야 하기 때문에
              데이터가 많아질수록 연산량이 O(N)으로 증가한다. 실제 사용 환경에서는 training이 오래 걸리더라도
              prediction이 빨라야 하므로 이 알고리즘은 실용성이 낮다. 또한, 단순 픽셀값의 차이는 이미지 내 물체의 위치나
              방향 등을 고려하지 않기 때문에 이미지에 대한 고차원적인 이해가 불가능하다.
            </p>

            <h2>Data Splitting</h2>
            <p>
              본격적으로 뉴럴 네트워크를 이용한 이미지 분류에 들어가기 앞서, 데이터셋을 어떻게 분류하고 모델을 훈련시킬
              수 있을지 알아보자.
            </p>
            <img src="/study/deep_learning_for_computer_vision/lecture_2/img5.png" alt="Data splitting" />
            <p>
              첫 번째 아이디어로, 우리가 가진 모든 데이터를 모델 훈련에 사용할 수 있다. 우리의 모델은 훈련된 이미지에는
              이미 완벽히 동작할 것이다. 훈련 시에는 이미지와 정답(라벨)을 주고 훈련시키기 때문이다. 그렇기 때문에 여러
              hyperparameter들을 조정해 가며 어떤 조합이 최적일지 찾는 것은 불가능하다.
            </p>
            <p>
              두 번째 아이디어로, 데이터를 training set과 test set으로 나눌 수 있다. training set을 이용해 모델을
              훈련시키고, test set 결과를 통해 가장 적합한 hyperparameter들을 구할 수 있다. 하지만 이 방법 또한
              완벽하지는 않은데, test set에만 잘 작동하는 hyperparameter를 구하게 될 수도 있기 때문이다.
            </p>
            <p>
              따라서, 데이터셋을 training set, validation set, test set의 세 가지로 분류하는 것이 좋다. Training set으로
              모델을 훈련시키고, validation set을 이용하여 hyperparameter tuning을 한다. 그 이후에 test set을 이용하여
              모델의 성능을 최종적으로 측정하는 것이다. 이 성능이 논문이나 보고서에 실리게 되는 숫자이다. 즉, 모델의
              훈련뿐만 아니라 hyperparameter tuning에도 test set이 영향을 미치지 않도록 해야 한다.
            </p>
            <img src="/study/deep_learning_for_computer_vision/lecture_2/img6.png" alt="Cross-validation" />
            <p>
              마지막으로, 데이터셋의 크기가 작을 때 주로 사용하는 Cross-Validation이라는 방법이 있다. 이 방법은 우선
              training set을 fold라는 단위로 균등하게 나눈 후, 각 fold를 돌아가면서 한 번씩 validation set으로 사용하는
              것이다. 이를 통해 더욱 정확한 validation 성능 측정이 가능하다. 하지만 fold의 수에 따라 연산량이 늘어나기
              때문에 데이터량이 매우 많은 딥러닝의 경우 잘 사용하지 않는다.
            </p>

            <h2>Linear Classifier</h2>
            <img src="/study/deep_learning_for_computer_vision/lecture_2/img7.png" alt="Linear classifier equation" />
            <p>
              kNN에서는 단순히 이미지 자체를 비교해서 분류를 수행하였다. 즉, 데이터셋 자체가 분류 모델이었다. 하지만
              앞으로 살펴볼 'parametric model'에서는 데이터셋에 대한 정보를 함축하여, 데이터셋 전체를 기억하지 않고도
              분류를 더욱 효율적으로 수행할 수 있다.
            </p>
            <p class="math-center">$\mathbf{y} = f(\mathbf{x}, \mathbf{W})$</p>
            <p>
              위 수식에서 $\mathbf{x}$는 입력된 픽셀값, $\mathbf{W}$는 데이터셋에 대한 정보가 함축된 'weight' 행렬,
              $f$는 $\mathbf{x}$와 $\mathbf{W}$를 이용하여 입력 이미지가 각 클래스에 속할 가능성을 클래스별 점수로
              출력하는 함수이다. 이 점수를 통해 가장 높은 점수를 가진 클래스를 선택할 수 있고, 우리는 데이터셋 전체를
              기억할 필요 없이 올바른 $\mathbf{W}$만을 갖고 있으면 쉽고 빠르게 분류를 수행할 수 있다.
            </p>
            <p>
              올바른 $\mathbf{W}$를 찾는 법은 다음 강의에서부터 살펴보기로 하고, $\mathbf{W}$가 있을 때 $\mathbf{x}$와
              $\mathbf{W}$를 어떻게 연산해야 할까? 가장 간단한 방법은 아래와 같이 단순히 픽셀값과 그에 해당하는 가중치를
              곱한 후 모두 더하는 것이다. 사칙연산만으로 이루어져 있기 때문에 linear classifier라는 명칭이 붙었다.
              이처럼 단순한 linear classifier는 대부분의 딥러닝 모델의 가장 기본적인 building block이 된다.
            </p>
            <p class="math-center">$f(\mathbf{x}, \mathbf{W}) = \mathbf{W} \cdot \mathbf{x} + \mathbf{b}$</p>
            <img src="/study/deep_learning_for_computer_vision/lecture_2/img8.png" alt="Linear classifier visualized" />
            <p>
              위 그림은 2x2 크기의 이미지를 3개의 클래스 중 하나로 분류하는 과정을 나타낸 것이다. 먼저 2x2 픽셀인
              이미지를 4x1의 1차원 벡터 $\mathbf{x}$로 펼친다. 이후 3x4의 weight matrix $\mathbf{W}$와 입력 벡터
              $\mathbf{x}$를 곱한 후 3x1의 bias 벡터 $\mathbf{b}$를 더하여 3x1의 점수 벡터를 만든다. 이 점수 벡터의 각
              원소는 입력 이미지가 해당 클래스에 속할 가능성을 나타낸다.
            </p>
            <p>
              <span class="color-red"> 이때, linear classification을 <b>template matching</b>으로 이해할 수 있다!</span>
            </p>
            <p>
              무슨 말인가 하면, $\mathbf{W}$의 각 row는 입력 이미지와 곱해져 하나의 클래스에 대한 점수를 만들어낸다. 첫
              번째 row는 cat, 두 번째 row는 dog, 세 번째 row는 ship에 대한 점수를 만들어내는 식이다. 그렇다면 각 row가
              어떨 때 점수가 가장 높을까?
            </p>
            <img src="/study/deep_learning_for_computer_vision/lecture_2/img9.jpg" alt="Template matching" />
            <p>
              우선 첫 번째 경우를 보면, $\mathbf{W}$의 한 row와 $\mathbf{x}$의 부호가 항상 반대이기 때문에 곱은 항상
              음수가 나온다. 따라서 쌍을 이루는 원소들의 부호가 같아야 점수가 높아짐을 알 수 있다. 두 번째 경우를 보면,
              $\mathbf{W}$와 $\mathbf{x}$의 그래프 형태가 유사하지 않다. 이 경우에는 예를 들어 $\mathbf{x}$의 마지막
              원소가 양수가 된다면 점수가 더 높아질 수 있다. 즉, 고양이에 해당하는 row는 고양이 사진이 들어왔을 때만
              높은 점수를 출력하고 다른 사진이 들어오면 낮은 점수를 출력해야 하는데 다른 클래스에 더 높은 점수를 줄 수도
              있는 것이다. 세 번째 경우를 보면, $\mathbf{W}$와 $\mathbf{x}$의 형태가 거의 일치한다. 이 경우 고양이
              사진에만 높은 점수를 출력하는 이상적인 $\mathbf{W}$가 된다.
            </p>
            <p>
              우리는 수많은 training 데이터셋으로 학습하므로, 결과적으로 $\mathbf{W}$의 각 row는 각 클래스에 해당하는
              이미지들을 한데 모아놓은 것 같은 형태가 된다. 실제로 CIFAR-10 데이터셋으로 학습시킨 $\mathbf{W}$의 각
              row를 이미지로 변환해보면 아래 그림과 같다.
            </p>
            <img src="/study/deep_learning_for_computer_vision/lecture_2/img10.png" alt="W visualization" />
            <p>
              car 클래스의 경우 자동차의 정면 형상이 보이며 deer 클래스의 경우 연두색 배경에 갈색 물체가 있는 등 각
              클래스에 해당하는 물체를 뭉뚱그려 놓은 듯한 형체가 보인다. 이때 중요한 것은 horse 클래스의 경우 말의
              머리가 양쪽에 달려 있는 것처럼 보이는데, 실제로 말의 머리가 양쪽에 달려 있는 이미지는 없다. 즉, linear
              classifier의 경우 한 클래스당 하나의 템플릿밖에 가지지 못하기 때문에 그 물체가 보여질 수 있는 모든 경우를
              뭉뚱그려 놓은 형태의 템플릿이 된다.
            </p>
            <img
              class="half"
              src="/study/deep_learning_for_computer_vision/lecture_2/img11.png"
              alt="Decision boundary"
            />
            <p>
              Linear classifier에 대한 또 다른 해석으로는 decision boundary가 있다. 대부분의 인공지능 교재에 많이 보이는
              그림인데, 이미지들을 고차원 평면상에 놓고 그 사이에 구분선을 그어 한 클래스와 다른 클래스들을 구분하는
              것이다. 즉, $f(\mathbf{x}, \mathbf{W})$의 결과가 특정 값보다 크면 그 클래스에 포함, 아니면 포함하지 않는
              것으로 보는 것이다. 이러한 해석을 통해 linear classification의 한계점을 파악할 수 있다.
            </p>
            <img
              src="/study/deep_learning_for_computer_vision/lecture_2/img12.png"
              alt="Decision boundary visualization"
            />
            <p>
              위 그림을 보면, 두 클래스의 하나의 직선으로 완전히 구분하는 것이 불가능하다. 왼쪽 경우처럼 픽셀의 수뿐만
              아니라 이미지 내 사람의 수를 홀수와 짝수로 분류하는 문제 등은 linear classifier로 해결하기 어렵다. 오른쪽
              경우처럼 한 클래스가 여러 곳에 퍼져 있는 경우도 있을 수 있는데, 위 horse 클래스에서 말이 왼쪽 또는 오른쪽
              둘 중 하나만 보고 있는 경우가 이에 해당된다. 이 또한 두 경우를 한꺼번에 다른 클래스와 구분짓는 것은
              어렵다. 결국 이 문제는 linear classifier를 다층으로 쌓아서 해결할 수 있는데, 이는 추후 강의에서 살펴볼
              예정이다.
            </p>

            <h2>Summary</h2>
            <img
              class="half"
              src="/study/deep_learning_for_computer_vision/lecture_2/img13.png"
              alt="Linear classifier summary"
            />
            <p>
              이번 강의에서는 linear classifier가 어떻게 작동하는지, $\mathbf{W}$는 어떤 의미를 가지고 있는지
              살펴보았다. 다음 강의에서는 loss function과 optimization을 통해 어떻게 최적의 $\mathbf{W}$를 찾을 수
              있는지 알아본다.
            </p>
          </div>

          <div class="post-footer">
            <div class="post-footer-profile">
              <img src="/asset/cover.jpg" alt="Seongmin Jung" />
              <h1>Seongmin Jung</h1>
            </div>
            <h2>
              Other posts in
              <a href="/study/deep_learning_for_computer_vision.html">Deep Learning for Computer Vision</a> series
            </h2>
            <ul>
              <li>
                <a href="/study/deep_learning_for_computer_vision/lecture_2.html">
                  <span><b>Lecture 2 | Image Classification</b></span>
                  <time datetime="2024-03-26">March 26, 2024</time>
                </a>
              </li>
              <li>
                <a href="/study/deep_learning_for_computer_vision/lecture_1.html">
                  <span>Lecture 1 | Introduction to Convolutional Neural Networks for Visual Recognition</span>
                  <time datetime="2024-03-26">March 26, 2024</time>
                </a>
              </li>
            </ul>
          </div>
        </section>
      </div>
    </main>

    <footer>
      <p>&copy; 2024 Seongmin Jung<br />Designed and developed by Seongmin Jung</p>
    </footer>
  </body>
</html>
