<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Lecture 3: Linear Classifiers</title>
    <meta name="description" content="Seongmin Jung's personal website" />
    <meta name="keywords" content="Seongmin Jung, Robotics" />
    <meta name="author" content="Seongmin Jung" />
    <meta name="language" content="English" />
    <link rel="shortcut icon" href="/favicon.png" />

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-LL44K1WZ0G"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() {
        dataLayer.push(arguments);
      }
      gtag("js", new Date());
      gtag("config", "G-LL44K1WZ0G");
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}
      });
    </script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML" async></script>

    <!-- Load an icon library to show a hamburger menu (bars) on small screens -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" />
    <!-- import css -->
    <link rel="stylesheet" href="/css/index.css" />
    <!-- import js -->
    <script src="/js/script.js" defer></script>
  </head>

  <body>
    <header>
      <img class="cover" src="/asset/cover.jpg" alt="Seongmin Jung" />
      <h1 class="title"><a href="/index.html">Seongmin Jung</a></h1>
      <nav class="nav">
        <a href="/index.html">Home</a>
        <a href="/projects.html">Projects</a>
        <a href="/study.html" class="bold">Study</a>
        <a href="/blog.html">Blog</a>
        <i id="nav-toggle" class="nav-toggle fa fa-bars" onclick="toggleNav()"></i>
      </nav>
    </header>

    <div id="nav-modal-bg" onclick="toggleNav()"></div>
    <nav id="nav-modal">
      <a href="/index.html">Home</a>
      <a href="/projects.html">Projects</a>
      <a href="/study.html" class="bold">Study</a>
      <a href="/blog.html">Blog</a>
    </nav>

    <main>
      <div class="container">
        <section id="post">
          <a id="series-tag" href="/study/deep_learning_for_computer_vision.html"
            ><i class="fa fa-book"></i> Deep Learning for Computer Vision</a
          >
          <h1>Lecture 3: Linear Classifiers</h1>
          <p class="date">Posted on <time datetime="2024-03-26">March 26, 2024</time></p>
          <div class="post-body">
            <h2>Linear Classifier</h2>
            <img src="/study/deep_learning_for_computer_vision/lecture_3/img1.png" alt="Linear classifier equation" />
            <p>
              kNN에서는 단순히 이미지 자체를 비교해서 분류를 수행하였다. 즉, 데이터셋 자체가 분류 모델이었다. 하지만
              앞으로 살펴볼 'parametric model'에서는 데이터셋에 대한 정보를 함축하여, 데이터셋 전체를 기억하지 않고도
              분류를 더욱 효율적으로 수행할 수 있다.
            </p>
            <p class="math-center">$\mathbf{y} = f(\mathbf{x}, \mathbf{W})$</p>
            <p>
              위 수식에서 $\mathbf{x}$는 입력된 픽셀값, $\mathbf{W}$는 데이터셋에 대한 정보가 함축된 'weight' 행렬,
              $f$는 $\mathbf{x}$와 $\mathbf{W}$를 이용하여 입력 이미지가 각 클래스에 속할 가능성을 클래스별 점수로
              출력하는 함수이다. 이 점수를 통해 가장 높은 점수를 가진 클래스를 선택할 수 있고, 우리는 데이터셋 전체를
              기억할 필요 없이 올바른 $\mathbf{W}$만을 갖고 있으면 쉽고 빠르게 분류를 수행할 수 있다.
            </p>
            <p>
              올바른 $\mathbf{W}$를 찾는 법은 아래쪽에서 살펴보기로 하고, 우선 $\mathbf{W}$가 있을 때 $\mathbf{x}$와
              $\mathbf{W}$를 어떻게 연산해야 할지 살펴보자. 가장 간단한 방법은 아래와 같이 단순히 픽셀값과 그에 해당하는
              가중치를 곱한 후 모두 더하는 것이다. 사칙연산만으로 이루어져 있기 때문에 linear classifier라는 명칭이
              붙었다. 이처럼 단순한 linear classifier는 대부분의 딥러닝 모델의 가장 기본적인 building block이 된다.
            </p>
            <p class="math-center">$f(\mathbf{x}, \mathbf{W}) = \mathbf{W} \cdot \mathbf{x} + \mathbf{b}$</p>
            <img src="/study/deep_learning_for_computer_vision/lecture_3/img2.png" alt="Linear classifier visualized" />
            <p>
              위 그림은 2x2 크기의 이미지를 3개의 클래스 중 하나로 분류하는 과정을 나타낸 것이다. 먼저 2x2 픽셀인
              이미지를 4x1의 1차원 벡터 $\mathbf{x}$로 펼친다. 이후 3x4의 weight matrix $\mathbf{W}$와 입력 벡터
              $\mathbf{x}$를 곱한 후 3x1의 bias 벡터 $\mathbf{b}$를 더하여 3x1의 점수 벡터를 만든다. 이 점수 벡터의 각
              원소는 입력 이미지가 해당 클래스에 속할 가능성을 나타낸다.
            </p>
            <p>
              <span class="color-red"> 이때, linear classification을 <b>template matching</b>으로 이해할 수 있다!</span>
            </p>
            <p>
              무슨 말인가 하면, $\mathbf{W}$의 각 row는 입력 이미지와 곱해져 하나의 클래스에 대한 점수를 만들어낸다. 첫
              번째 row는 cat, 두 번째 row는 dog, 세 번째 row는 ship에 대한 점수를 만들어내는 식이다. 그렇다면 각 row가
              어떨 때 점수가 가장 높을까?
            </p>
            <img src="/study/deep_learning_for_computer_vision/lecture_3/img3.jpg" alt="Template matching" />
            <p>
              우선 첫 번째 경우를 보면, $\mathbf{W}$의 한 row와 $\mathbf{x}$의 부호가 항상 반대이기 때문에 곱은 항상
              음수가 나온다. 따라서 쌍을 이루는 원소들의 부호가 같아야 점수가 높아짐을 알 수 있다. 두 번째 경우를 보면,
              $\mathbf{W}$와 $\mathbf{x}$의 그래프 형태가 유사하지 않다. 이 경우에는 예를 들어 $\mathbf{x}$의 마지막
              원소가 양수가 된다면 점수가 더 높아질 수 있다. 즉, 고양이에 해당하는 row는 고양이 사진이 들어왔을 때만
              높은 점수를 출력하고 다른 사진이 들어오면 낮은 점수를 출력해야 하는데 다른 클래스에 더 높은 점수를 줄 수도
              있는 것이다. 세 번째 경우를 보면, $\mathbf{W}$와 $\mathbf{x}$의 형태가 거의 일치한다. 이 경우 고양이
              사진에만 높은 점수를 출력하는 이상적인 $\mathbf{W}$가 된다.
            </p>
            <p>
              우리는 수많은 training 데이터셋으로 학습하므로, 결과적으로 $\mathbf{W}$의 각 row는 각 클래스에 해당하는
              이미지들을 한데 모아놓은 것 같은 형태가 된다. 실제로 CIFAR-10 데이터셋으로 학습시킨 $\mathbf{W}$의 각
              row를 이미지로 변환해보면 아래 그림과 같다.
            </p>
            <img src="/study/deep_learning_for_computer_vision/lecture_3/img4.png" alt="W visualization" />
            <p>
              car 클래스의 경우 자동차의 정면 형상이 보이며 deer 클래스의 경우 연두색 배경에 갈색 물체가 있는 등 각
              클래스에 해당하는 물체를 뭉뚱그려 놓은 듯한 형체가 보인다. 이때 중요한 것은 horse 클래스의 경우 말의
              머리가 양쪽에 달려 있는 것처럼 보이는데, 실제로 말의 머리가 양쪽에 달려 있는 이미지는 없다. 즉, linear
              classifier의 경우 한 클래스당 하나의 템플릿밖에 가지지 못하기 때문에 그 물체가 보여질 수 있는 모든 경우를
              뭉뚱그려 놓은 형태의 템플릿이 된다.
            </p>
            <img
              class="half"
              src="/study/deep_learning_for_computer_vision/lecture_3/img5.png"
              alt="Decision boundary"
            />
            <p>
              Linear classifier에 대한 또 다른 해석으로는 decision boundary가 있다. 대부분의 인공지능 교재에 많이 보이는
              그림인데, 이미지들을 고차원 평면상에 놓고 그 사이에 구분선을 그어 한 클래스와 다른 클래스들을 구분하는
              것이다. 즉, $f(\mathbf{x}, \mathbf{W})$의 결과가 특정 값보다 크면 그 클래스에 포함, 아니면 포함하지 않는
              것으로 보는 것이다. 이러한 해석을 통해 linear classification의 한계점을 파악할 수 있다.
            </p>
            <img
              src="/study/deep_learning_for_computer_vision/lecture_3/img6.png"
              alt="Decision boundary visualization"
            />
            <p>
              위 그림을 보면, 두 클래스의 하나의 직선으로 완전히 구분하는 것이 불가능하다. 왼쪽 경우처럼 픽셀의 수뿐만
              아니라 이미지 내 사람의 수를 홀수와 짝수로 분류하는 문제 등은 linear classifier로 해결하기 어렵다. 오른쪽
              경우처럼 한 클래스가 여러 곳에 퍼져 있는 경우도 있을 수 있는데, 위 horse 클래스에서 말이 왼쪽 또는 오른쪽
              둘 중 하나만 보고 있는 경우가 이에 해당된다. 이 또한 두 경우를 한꺼번에 다른 클래스와 구분짓는 것은
              어렵다. 결국 이 문제는 linear classifier를 다층으로 쌓아서 해결할 수 있는데, 이는 추후 강의에서 살펴볼
              예정이다.
            </p>

            <h2>Loss Function</h2>
            <img
              class="half"
              src="/study/deep_learning_for_computer_vision/lecture_3/img7.png"
              alt="Linear classifier summary"
            />
            <p>
              지금까지 linear classifier가 어떻게 작동하는지, $\mathbf{W}$는 어떤 의미를 가지고 있는지 살펴보았다.
              그렇다면 최적의 $\mathbf{W}$를 어떻게 찾을 수 있을까? 이를 위해서는 먼저 $\mathbf{W}$가 얼마나 좋고
              나쁜지를 수치화해야 한다. 이를 loss function이라고 한다. 이미지 한 개에 대한 loss function은 아래와 같이
              정의할 수 있다.
            </p>
            <p class="math-center">$L_i(f(\mathbf{x}_i, \mathbf{W}), y_i)$</p>
            <p>
              즉, 특정 입력값에 대한 예측값과 정답을 비교하여 얼마나 잘못 예측했는지를 수치화한 것이다. 이를 모든
              데이터셋에 대해 적용한 전체 loss function은 아래와 같이 정의할 수 있다.
            </p>
            <p class="math-center">
              $L(\mathbf{W}) = \frac{1}{N} \sum_{i=1}^{N} L_i(f(\mathbf{x}_i, \mathbf{W}), y_i)$
            </p>

            <h3>Multiclass SVM Loss</h3>
            <p>
              Multiclass SVM Loss의 개념은, 단순하게 정답인 클래스의 점수가 다른 모든 클래스의 점수보다도 어느 정도
              높아야 한다는 것이다. 이를 수식으로 나타내면 아래와 같다.
            </p>
            <p class="math-center">$L_i = \sum_{j \neq y_i} \max(0, s_j - s_{y_i} + 1)$</p>
            <img
              class="half"
              src="/study/deep_learning_for_computer_vision/lecture_3/img8.png"
              alt="Multiclass SVM Loss"
            />
            <p>
              정답 클래스의 점수가 다른 한 클래스의 점수보다 1 이상 높다면 loss는 0이 된다. 반면 정답 클래스의 점수가
              다른 클래스의 점수 + 1보다 낮다면, 그 둘의 차이가 그 클래스에 대한 loss 성분이 된다. 이를 정답 클래스를
              제외한 모든 클래스에 대해 수행하고 모두 더하면 해당 이미지에 대한 loss가 된다.
            </p>
            <img
              class="half"
              src="/study/deep_learning_for_computer_vision/lecture_3/img9.png"
              alt="Multiclass SVM Loss calaulation"
            />
            <p>
              예를 들어, 위 그림과 같이 3개의 인풋 이미지와 3개의 클래스가 있을 때 고양이 이미지에 대한 SVM loss를
              계산해 보자.
            </p>
            <p class="math-center">
              $L_i = \sum_{j \neq y_i} \max(0, s_j - s_{y_i} + 1) = \max(0, 5.1 - 3.2 + 1) + \max(0, -1.7 - 3.2 + 1) =
              2.9$
            </p>
            <p>Q: 자동차 이미지에 대한 점수들을 아주 약간씩 조절하면 loss에는 어떤 변화가 생길까?</p>
            <p>
              A: 정답 클래스의 점수가 다른 클래스의 점수보다 1 이상 높기 때문에 loss에는 변화가 없다. 이는 SVM loss의
              경우 정답 클래스를 맞추기만 하면 점수 자체에는 큰 의미가 없다는 것을 뜻한다.
            </p>
            <p>Q: 가능한 loss의 최댓값과 최솟값은?</p>
            <p>A: 최댓값은 무한대이고, 최솟값은 정답 클래스의 점수가 다른 클래스의 점수보다 1 이상 높을 때 0이다.</p>
            <p>Q: Training 초기, 모든 점수가 작은 random 값일 때 loss는?</p>
            <p>
              A: 모든 클래스의 점수 차가 0에 가까울 것이기 때문에 모든 loss 성분이 1이 된다. 따라서 총 loss는 C - 1이다.
            </p>
          </div>

          <div class="post-footer">
            <div class="post-footer-profile">
              <img src="/asset/cover.jpg" alt="Seongmin Jung" />
              <h1>Seongmin Jung</h1>
            </div>
            <h2>
              Other posts in
              <a href="/study/deep_learning_for_computer_vision.html">Deep Learning for Computer Vision</a> series
            </h2>
            <ul>
              <li>
                <a href="/study/deep_learning_for_computer_vision/lecture_3.html">
                  <span><b>Lecture 3: Linear Classifiers</b></span>
                  <time datetime="2024-03-28">March 28, 2024</time>
                </a>
              </li>
              <li>
                <a href="/study/deep_learning_for_computer_vision/lecture_2.html">
                  <span>Lecture 2: Image Classification</span>
                  <time datetime="2024-03-26">March 26, 2024</time>
                </a>
              </li>
              <li>
                <a href="/study/deep_learning_for_computer_vision/lecture_1.html">
                  <span>Lecture 1: Introduction to Deep Learning for Computer Vision</span>
                  <time datetime="2024-03-26">March 26, 2024</time>
                </a>
              </li>
            </ul>
          </div>
        </section>
      </div>
    </main>

    <footer>
      <p>&copy; 2024 Seongmin Jung<br />Designed and developed by Seongmin Jung</p>
    </footer>
  </body>
</html>
