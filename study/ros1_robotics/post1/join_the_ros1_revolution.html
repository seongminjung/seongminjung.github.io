<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>1. Join the ROS1 Revolution!</title>
    <meta name="description" content="Seongmin Jung's personal website" />
    <meta name="keywords" content="Seongmin Jung, Robotics" />
    <meta name="author" content="Seongmin Jung" />
    <meta name="language" content="English" />
    <link rel="shortcut icon" href="/favicon.png" />

    <!-- Google tag (gtag.js) -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=G-LL44K1WZ0G"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag() {
        dataLayer.push(arguments);
      }
      gtag("js", new Date());
      gtag("config", "G-LL44K1WZ0G");
    </script>

    <!-- Load an icon library to show a hamburger menu (bars) on small screens -->
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" />
    <!-- import css -->
    <link rel="stylesheet" href="/css/index.css" />
    <!-- import js -->
    <script src="/js/script.js" defer></script>
  </head>

  <body>
    <header>
      <img class="cover" src="/asset/cover.jpg" alt="Seongmin Jung" />
      <h1 class="title"><a href="/index.html">Seongmin Jung</a></h1>
      <nav class="nav">
        <a href="/index.html">Home</a>
        <a href="/projects.html">Projects</a>
        <a href="/study.html" class="bold">Study</a>
        <i id="nav-toggle" class="nav-toggle fa fa-bars" onclick="toggleNav()"></i>
      </nav>
    </header>

    <div id="nav-modal-bg" onclick="toggleNav()"></div>
    <nav id="nav-modal">
      <a href="/index.html">Home</a>
      <a href="/projects.html">Projects</a>
      <a href="/study.html" class="bold">Study</a>
    </nav>

    <main>
      <div class="container">
        <section id="projects">
          <h3>
            1. Join the ROS1 revolution! A step-by-step guide to installing and setting up the Robot Operating System
          </h3>
          <div class="project" id="project-3">
            <div class="grid">
              <h4>HeightGrid</h4>
              <img class="preview" src="img/project/project3/preview.png" alt="preview" />
              <p class="detail">
                I enhanced pose tracking by integrating scene understanding. I utilized vertically oriented objects in
                urban settings, such as poles and trees, as landmarks. I created HeightGrid, an innovative 2D grid data
                structure that records the vertical extent of these objects, efficiently condensing the spatial
                information into a representative value. Then, I developed a novel pose-tracking algorithm based on 2D
                Iterative Closest Point (ICP). In the process, each cell was assigned a weight proportional to its
                height value, considering the significance of each cell's spatial contribution. This approach
                significantly reduced computational load while maintaining accuracy in relation to the 3D
                PointCloud-based pose-tracking algorithms.
              </p>
            </div>
          </div>
          <div class="project" id="project-2">
            <div class="grid">
              <h4>Agile Autonomous Navigation</h4>
              <img class="preview" src="img/project/project2/preview.png" alt="preview" />
              <p class="detail">
                In my undergraduate thesis, I led the software development of an agile autonomous navigation system
                based on scene understanding, without relying on traditional Simultaneous Localization and Mapping
                (SLAM). Our approach combined local path planning with path integration, allowing navigation toward the
                goal while avoiding obstacles. As a testing robot, we mounted a 2D LiDAR on a remote-controlled model
                car. I created an algorithm for line detection and obstacle clustering from the laser scan. This simple
                scene understanding facilitated the computation of optimal paths with reduced computational demands. I
                also elaborated a path integration algorithm by adopting an equation correlating the car's steering
                angle with the rotation radius. As a result, our robot reached an impressive average speed of 2m/s,
                while SLAM-based methods could move only a few centimeters per second in the same condition.
              </p>
            </div>
          </div>
          <div class="project" id="project-1">
            <div class="grid">
              <h4>Underwater Robot Simulation</h4>
              <img class="preview" src="img/project/project1/preview.png" alt="preview" />
              <p class="detail">
                At CWRUbotix, I developed a realistic underwater robot simulation for the MATE ROV World Championship
                2023. This involved using the Gazebo simulator and ROS to replicate real mission scenarios. The first
                challenge was buoyancy. With no water model in Gazebo, I adjusted the air density to 1000kg/m<sup
                  >3</sup
                >
                and fine-tuned the robot model's mass. Second, I precisely modeled the eight thrusters' power and blade
                arrangement, applying fluid dynamics principles. Lastly, I integrated ROS for maneuverability and
                stabilization, mirroring the actual robot's autopilot system. As a result, our simulation evolved into a
                realistic platform for testing mission execution.
              </p>
            </div>
          </div>
        </section>
      </div>
    </main>

    <footer>
      <p>&copy; 2024 Seongmin Jung<br />Designed and developed by Seongmin Jung</p>
    </footer>
  </body>
</html>
