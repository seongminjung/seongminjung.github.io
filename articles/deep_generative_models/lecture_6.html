<!DOCTYPE html>
<html lang="en">
  <head>
    <link rel="stylesheet" href="/css/index.css" />
    <script type="module" src="/js/main.js" defer></script>
  </head>

  <body>
    <web-head></web-head>
    <web-header></web-header>

    <main>
      <div class="container">
        <section id="post">
          <post-header></post-header>

          <div class="post-body">
            <h2>Variational Inference</h2>
            <p>
              지난 강의에서, latent variable $\mathbf{z}$의 분포를 임의로 모델링하기 위해 $q(\mathbf{z})$를 도입하였다.
              이 $q(\mathbf{z})$를 이용하여 ELBO를 유도하고, 최종 목표인 데이터의 likelihood $p(\mathbf{x})$를 최대화할
              수 있다. 이러한 전반적인 과정을 variational inference라고 한다.
            </p>
            <p>
              이러한 과정이 필요했던 이유는, $\mathbf{z}$로부터 $\mathbf{x}$를 추정하는 모델을 학습시키기 위해서는
              $\mathbf{z}$가 주어져야 하는데, 우리가 가진 데이터셋은 $\mathbf{x}$밖에 없기 때문이다. 따라서 우회적인
              방법으로 $\mathbf{x}$로부터 $\mathbf{z}$를 추정하는 모델을 도입했는데 그것이 바로 $q(\mathbf{z})$이다.
            </p>
            <p>
              지난 강의에서 언급했듯 이론상 $q(\mathbf{z}) = p(\mathbf{z} \mid \mathbf{x})$가 되면 ELBO의 등식이
              성립하여 optimal한 모델이 된다. 하지만 실제로는 뉴럴 네트워크를 이용하여 $p(\mathbf{z} \mid \mathbf{x})$에
              가까이 가기 위한 optimization 문제를 풀게 된다.
            </p>
            <p>두 분포 $q(\mathbf{z})$와 $p(\mathbf{z} \mid \mathbf{x})$ 사이의 KL Divergence를 구해 보자.</p>
            <p class="math-center">
              $D_{KL}(q(\mathbf{z}) \| p(\mathbf{z} \mid \mathbf{x} ; \theta)) = - \sum\limits_{\mathbf{z}}
              q(\mathbf{z}) \log p(\mathbf{z}, \mathbf{x} ; \theta) + \log p(\mathbf{x} ; \theta) - H(q) \geq 0$
            </p>
            <p>위 식의 부등호 부분을 아래와 같이 정리할 수 있다.</p>
            <p class="math-center">
              $\log p(\mathbf{x} ; \theta) \geq \sum\limits_{\mathbf{z}} q(\mathbf{z}) \log p(\mathbf{z}, \mathbf{x} ;
              \theta) + H(q)$
            </p>
            <p>
              이전 강의에서의 ELBO 식이 나온다는 것을 알 수 있다. 이처럼 KL Divergence를 이용해서도 ELBO를 최대화하는
              것이 $q(\mathbf{z})$가 $p(\mathbf{z} \mid \mathbf{x})$에 가까워지도록 하는 것과 같음을 보일 수 있다.
            </p>
            <p>
              하지만 문제는 VAE에서는 $p(\mathbf{z} \mid \mathbf{x})$를 직접 구할 수 없다는 것이다. $p(\mathbf{x} \mid
              \mathbf{z})$가 뉴럴 네트워크로 정의되기 때문에 조건부 확률을 뒤집는 것을 수식적으로 계산할 수 없다. 따라서
              VAE에서는 새로운 뉴럴 네트워크를 도입하여 $p(\mathbf{z} \mid \mathbf{x})$를 모델링한다. 이 뉴럴 네트워크의
              확률분포를 $q(\mathbf{z} ; \phi)$라 하자.
            </p>
            <p>
              이때 뉴럴 네트워크 $q(\mathbf{z} ; \phi)$를 VAE의 encoder, $p(\mathbf{x} \mid \mathbf{z} ; \theta)$를
              decoder라 한다.
            </p>
            <img class="half" src="/articles/deep_generative_models/lecture_6/img1.png" alt="ELBO" />
            <p>
              이 optimization 과정을 도식화하면 위와 같다. 어떤 이미지 $\mathbf{x}$와 decoder 파라미터 $\theta$가
              주어졌을 때, log probability $\log p_\theta(\mathbf{x})$는 우리가 모르는 어떤 상수이다.
              $q_\phi(\mathbf{z})$의 파라미터 $\phi$가 변함에 따라 KL Divergence도 변함을 알 수 있다. 따라서 VAE의
              전략은 encoder 파라미터 $\phi$와 decoder 파라미터 $\theta$를 joint training하는 것이다.
            </p>
            <img class="half" src="/articles/deep_generative_models/lecture_6/img2.png" alt="Joint training" />
            <p>
              $\phi$와 $\theta$를 동시에 optimization하는 상황을 도식화하면 위와 같다. $\phi$를 통해 실제 marginal
              likelihood가 높은 곳에 높은 확률분포를 가지도록 곡선을 선택하고, $\theta$는 한 곡선 안에서 실제 marginal
              likelihood와의 차이가 최소가 되는 지점을 찾는다.
            </p>

            <h2>Training over the Entire Dataset</h2>
            <p class="math-center">
              $\ell(\theta ; \mathcal{D}) = \sum\limits_{\mathbf{x}^i \in \mathcal{D}} \log p(\mathbf{x}^i ; \theta)
              \geq \sum\limits_{\mathbf{x}^i \in \mathcal{D}} \mathcal{L}(\mathbf{x}^i ; \theta, \phi^i)$
            </p>
            <p>
              전체 데이터셋에 대해 학습하기 위해 위와 같이 각 이미지에 대한 log likelihood의 합으로 objective function을
              구성한다. ELBO도 마찬가지로 각 이미지에 대한 값을 모두 합하여 구한다.
            </p>
            <p>
              이때 ELBO를 정확하게 계산하려면 각 data point $\mathbf{x}^i$에 대해 서로 다른 확률분포 $q(\mathbf{z} ;
              \phi^i)$가 필요하다는 문제점이 있다. 각 data point마다 그 데이터가 생성되었을 latent vector의 기댓값과
              분산이 모두 다를 것이기 때문이다.
            </p>
            <p>
              그렇기 때문에 실제 VAE에서는 공통된 뉴럴 네트워크로 $q(\mathbf{z} ; \phi)$를 예측하지만, motivation을 위해
              아래 두 섹션에서는 $q(\mathbf{z} ; \phi^i)$가 뉴럴 네트워크가 아니라 단순히 변수 $\phi^i$에 의해 정해지는
              확률분포로 보자. 즉, $\phi^i_1$이 기댓값, $\phi^i_2$가 분산이 되어 $\mathbf{z}$가 어떤 값이었을지에 대한
              확률분포를 각 데이터 $\mathbf{x}^i$에 대해 직접 결정하는 것이다.
            </p>

            <h3>Learning via Stochastic Variational Inference (SVI)</h3>
            <p class="math-center">
              $\mathcal{L}(\mathbf{x}^i ; \theta, \phi^i) = \mathbb{E}_{q(\mathbf{z}; \phi^i)} [ \log p(\mathbf{z},
              \mathbf{x}^i ; \theta) - \log q(\mathbf{z}; \phi^i)]$
            </p>
            <p>
              ELBO를 최대화하기 위한 가장 간단한 방법은 위의 ELBO 식에 대해 gradient ascent를 사용하는 것이다. 먼저 각
              파라미터 $\theta, \phi^1, \cdots, \phi^M$을 initialize한다. 이후 $\phi^i$에 대해 먼저 gradient를 구하여
              optimization을 진행한다. $\phi^i$가 수렴값에 도달하면 $\theta$를 한 스텝 업데이트한다. 이 과정을
              $\theta$가 수렴할 때까지 반복한다.
            </p>

            <h3>Reparameterization Trick</h3>
            <p>
              이때 $\theta$에 대한 gradient는 구하기 쉬운데, $\phi^i$에 대한 gradient는 직접 구할 수 없다. $\phi^i$로
              정의되는 확률분포에서 $\mathbf{z}$를 샘플링하는 과정은 미분이 불가능하기 때문이다. 따라서
              Reparameterization trick을 이용하여 이를 해결한다.
            </p>
            <p>
              Reparameterization trick은 먼저, $q(\mathbf{z}; \phi)$를 기댓값이 $\mu$, 분산이 $\sigma^2I$인 가우시안
              분포라고 가정한다. 첨자 $i$는 생략한다. $\phi_1$이 기댓값, $\phi_2$가 분산이 된다. 이 분포에서 샘플을 하나
              뽑는 과정을 아래와 같이 두 단계로 나누어 생각할 수 있다.
            </p>
            <ol>
              <li>$\mathcal{N}(0, I)$에서 샘플 $\epsilon$을 하나 뽑는다.</li>
              <li>$\mathbf{z} = \mu + \sigma\epsilon$을 통해 $\mathbf{z}$를 계산한다.</li>
            </ol>
            <p>
              이 과정을 통해 $\mu$와 $\sigma$가 미분 가능한 방식으로 ELBO에 영향을 미치게 되므로 gradient를 구할 수
              있다.
            </p>
            <p class="math-center">
              $\displaystyle \mathbb{E}_{\mathbf{z} \sim q(\mathbf{z}; \phi)} [r(\mathbf{z})] = \int q(\mathbf{z}; \phi)
              r(\mathbf{z}) d\mathbf{z} = \mathbb{E}_{\boldsymbol{\epsilon} \sim \mathcal{N}(0, I)}
              [r(g(\boldsymbol{\epsilon}; \phi))] = \int \mathcal{N}(\boldsymbol{\epsilon}) r(\mu + \sigma
              \boldsymbol{\epsilon}) d\boldsymbol{\epsilon}$
            </p>
            <p>
              수식을 간단히 하기 위해 원래 ELBO 식의 기댓값 안의 식을 $r(\mathbf{z})$로 치환하면 위 식과 같이 쓸 수
              있다. 즉 정해진 분포 $\mathcal{N}(0, I)$에 대하여 기댓값을 구하는 것이기 때문에 gradient 계산이 가능하다.
            </p>
            <p class="math-center">
              $\nabla_{\phi} \mathbb{E}_{q(\mathbf{z}; \phi)} [r(\mathbf{z})] = \nabla_{\phi}
              \mathbb{E}_{\boldsymbol{\epsilon}} [r(g(\boldsymbol{\epsilon}; \phi))] =
              \mathbb{E}_{\boldsymbol{\epsilon}} [\nabla_{\phi} r(g(\boldsymbol{\epsilon}; \phi))]$
            </p>
            <p>위 식과 같이 gradient $\nabla_{\phi}$를 기댓값 연산 전에 계산할 수 있게 된다.</p>
            <p class="math-center">
              $\mathbb{E}_{\boldsymbol{\epsilon}} [\nabla_{\phi} r(g(\boldsymbol{\epsilon}; \phi))] \approx \cfrac{1}{K}
              \sum\limits_{k} \nabla_{\phi} r(g(\boldsymbol{\epsilon}^k; \phi))$
            </p>
            <p>이제 Monte Carlo를 이용하여 위 식과 같이 기댓값을 표본평균으로 근사하여 구할 수 있다.</p>

            <h3>Amortized Inference</h3>
          </div>

          <post-footer></post-footer>
        </section>
      </div>
    </main>

    <footer>
      <p>&copy; 2025 Seongmin Jung<br />Designed and developed by Seongmin Jung</p>
    </footer>
  </body>
</html>
