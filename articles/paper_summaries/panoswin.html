<!DOCTYPE html>
<html lang="en">
  <head>
    <link rel="stylesheet" href="/css/index.css" />
    <script type="module" src="/js/main.js" defer></script>
  </head>

  <body>
    <web-head></web-head>
    <web-header></web-header>

    <main>
      <div class="container">
        <section id="post">
          <post-header></post-header>

          <div class="post-body">
            <arxiv-card
              title="PanoSwin: a Pano-style Swin Transformer for Panorama Understanding"
              venue="CVPR 2023"
              authors="Zhixin Ling, Zhen Xing, Xiangdong Zhou, Manliang Cao, Guichun Zhou"
              link="https://arxiv.org/abs/2308.14726"
            >
            </arxiv-card>

            <h2>Introduction</h2>
            <p>본 논문은 equirect 이미지를 트랜스포머에서 다루는 방법을 종합적으로 설명한다.</p>
            <p>
              기존 핀홀 이미지로 학습된 모델은 equirect 이미지에 적용하기 적합하지 않다. 특히, equirect 이미지는 좌우 양
              끝이 이어져 있는데, 이는 핀홀 모델로 표현 불가능하다. 또한 equirect 이미지의 특성으로 인해 기존 트랜스포머
              아키텍쳐와 positional encoding 방식도 달라져야 한다.
            </p>
            <p>PanoSwin은 equirect 이미지에 특화된 트랜스포머로, contribution은 아래와 같다.</p>
            <ul>
              <li>Pano-style 윈도우 attention 제안</li>
              <li>좌우 양 끝의 연결성을 유지한 positional encoding</li>
              <li>핀홀 이미지로 먼저 학습 후 knowledge distillation 가능</li>
            </ul>

            <h2>Related Work</h2>

            <h4>Vision Transformer</h4>
            <p>지금까지 다양한 ViT 구조가 제안되었지만, 핀홀 기반 ViT는 파노라마 구조를 반영하기 어렵다.</p>

            <h4>Panorama Representation Learning</h4>
            <p>
              초기에는 구면에서 CNN 기반으로 모델을 구축하였다(e.g. S2CNN, SpherePHD). 최근에는 파노라마를 위한
              transformer 시도가 존재한다(e.g. PanoFormer).
            </p>

            <h2>Method</h2>

            <h3>Preliminaries of Swin Transformer</h3>
            <img class="half" src="/articles/paper_summaries/panoswin/img2.png" alt="Window attention" />
            <p>Window attention은 Swin Transformer에서 새롭게 도입한 개념이다.</p>
            <ul>
              <li>각 window 안에서만 self-attention 수행</li>
              <li>Layer별로 window의 위치를 shift</li>
              <li>피라미드 구조 $\rightarrow$ layer가 깊어질수록 window를 합쳐서 size 감소, 채널 수 증가</li>
            </ul>

            <h3>Pano-style Shift Windowing Scheme</h3>
            <img src="/articles/paper_summaries/panoswin/img1.png" alt="Pano-style Shift Windowing Scheme" />
            <ul>
              <li>파노라마 이미지는 왼쪽/오른쪽이 연결됨</li>
              <li>Window가 수평/수직 경계를 넘어가면 반대쪽 window와 연결되도록 설정</li>
              <li>옮긴 window 내부에서 attention 수행</li>
            </ul>

            <h3>Panoramic Rotation</h3>
            <img class="half" src="/articles/paper_summaries/panoswin/img3.png" alt="Panoramic Rotation" />
            <p>
              Data augmentation에 사용되는 방식으로, equirect 이미지의 north pole을 옮김으로써 발생하는 이미지의 왜곡을
              모델링한다.
            </p>

            <h3>Pitch Attention Module</h3>
            <img class="half" src="/articles/paper_summaries/panoswin/img4.png" alt="Pitch Attention Module" />
            <p>
              North/south pole 부분의 왜곡을 완화하는 모듈이다. 왜곡이 심한 영역을 회전시켜 덜 왜곡된 시야에서 다시 보게
              만든다. 아래의 3단계로 구성되어 있다.
            </p>
            <ol>
              <li>90도 아래를 보도록 회전 (Panoramic Rotation 공식 이용)</li>
              <li>원래 이미지에서의 window 중심점을 회전시킨 이미지로 projection하고, 새롭게 window 설정</li>
              <li>기존 window들과 새로운 window들 간 cross-attention</li>
            </ol>

            <h3>Pano-style Positional Encodings</h3>
            <p>
              각 window의 절대적 위치와 window간 상대적 위치를 모두 활용한다. APE로는 직교좌표계 및 구면좌표계 좌표를
              모두 활용한다. 좌표값을 MLP에 통과시켜 얻은 벡터를 각 window의 embedding에 더해 준다.
            </p>
            <p>RPE로는 구면 거리인 great-circle distance를 활용한다.</p>

            <h3>Two-Stage Learning Paradigm</h3>
            <p>최종 아키텍쳐는 아래와 같다.</p>
            <img src="/articles/paper_summaries/panoswin/img5.png" alt="PanoSwin Architectures" />
            <p>(W: 기본 window attention, PSW: pano shift attention, PA: pitch attention, PM: patch merging)</p>
            <p>학습은 planar stage와 panoramic stage의 두 단계로 나뉘어 이루어진다.</p>

            <h4>Planar stage: 핀홀 모델처럼 학습</h4>
            <p>
              Equirect 이미지를 핀홀 이미지로 간주하고 downstream task에 대해 학습한다. Pitch attention을 기본 cross
              attention으로 대체하고 구면좌표계에서의 positional encoding 모두 disable한다. Equirect 이미지의 중심
              부분은 왜곡이 적으므로 그 정보를 학습하는 것이 목적이다.
            </p>

            <h4>Panoramic Stage: Equirect 이미지로 distillation</h4>
            <p>
              앞서 학습한 모델을 teacher로 삼아 equirect 이미지를 처리할 수 있도록 학습한다. Pitch attention 및
              positional encoding 모두 enable한다. 이 단계에서는 KP loss를 도입하는데, 중앙 영역은 teacher를 따라가고,
              주변 영역은 panorama-aware하게 fine-tuning하는 역할을 한다.
            </p>
          </div>

          <post-footer></post-footer>
        </section>
      </div>
    </main>

    <footer>
      <p>&copy; 2025 Seongmin Jung<br />Designed and developed by Seongmin Jung</p>
    </footer>
  </body>
</html>
