<!DOCTYPE html>
<html lang="en">
  <head>
    <link rel="stylesheet" href="/css/index.css" />
    <script type="module" src="/js/main.js" defer></script>
  </head>

  <body>
    <web-head></web-head>
    <web-header></web-header>

    <main>
      <div class="container">
        <section id="post">
          <post-header></post-header>

          <div class="post-body">
            <arxiv-card
              title="Modeling Uncertainty in 3D Gaussian Splatting through Continuous Semantic Splatting"
              venue="ArXiv 2024.11"
              authors="Joey Wilson, Marcelino Almeida, Min Sun, Sachit Mahajan, Maani Ghaffari, Parker Ewen, Omid Ghasemalizadeh, Cheng-Hao Kuo, Arnie Sen"
              link="https://arxiv.org/abs/2411.02547"
            >
            </arxiv-card>

            <h2>Introduction</h2>
            <p>3DGS segmentation을 하는 기존 모델들이 fail하는 경우가 3가지 있다.</p>
            <ol>
              <li>2D에서 segmentation 정보를 넣어 주는 네트워크 자체에 노이즈가 많을 때.</li>
              <li>Novel view에서 보았을 때 필요한 곳에 가우시안이 존재하지 않을 때.</li>
              <li>Novel view에서 여러 객체의 경계가 흐려지면서 서로 다른 semantic category가 혼합될 때.</li>
            </ol>

            <h2>Method</h2>

            <h3>Preliminaries: Gaussian Splatting</h3>
            <p>
              3DGS의 각 가우시안은 중심점 $\mu$, 공분산 $\Sigma$, opacity $\alpha$ 등으로 정의된다. 중심점과 공분산은
              splatting 과정을 통해 2D image plane 상의 점 $\mu'$와 $\Sigma'$으로 변환된다. 2D 픽셀 $x_i'$와 splatting된
              가우시안 $x_n'$가 주어졌을 때, 점 $x_i'$에서의 가우시안 함숫값은 아래와 같다.
            </p>
            <p class="math-center">
              $g(x'_i, x'_n) = \exp \left( -\cfrac{1}{2} (x'_i - \mu'_n)^T \Sigma_n^{-1} (x'_i - \mu'_n) \right)$
            </p>
            <p>논문에서는 $k(x'_i, x'_n)$라고 표기했지만 뒤에 나올 $\kappa$와 구분하기 위해 $g$로 표기하였다.</p>
            <p>이후 아래의 식과 같이 이 함숫값을 opacity와 곱해 그 가우시안의 influence를 구한다.</p>
            <p class="math-center">$\alpha'_n = \alpha_n \cdot g(x'_i, x'_n)$</p>
            <p>아래와 같이 alpha compositing을 하여 occlusion을 반영한다.</p>
            <p class="math-center">$\kappa(x'_i, x'_n) = \alpha'_n \prod\limits_{j=1}^{n-1} (1 - \alpha'_j)$</p>
            <p>
              최종적으로 2D 픽셀 $x_i'$에서 쏜 ray 상에 있는 $N$개의 가우시안에 대해 앞에서 뒤 순서로 아래와 같이 합을
              구하면 그 픽셀의 색깔을 렌더링할 수 있다.
            </p>
            <p class="math-center">$C_i = \sum\limits_{n=1}^{N} c_n \kappa(x'_i, x'_n)$</p>
            <p>
              위의 유도 과정을 살펴보면, $\kappa(x'_i, x'_n)$가 $n$번째 가우시안이 $i$번째 픽셀 $x'_i$에 미치는 영향을
              0부터 1 사이의 값으로 나타내고 있는 것을 볼 수 있다.
            </p>

            <h3>Probabilistic Semantic Update</h3>
            <p>
              여기서는 이미 학습이 완료된 각 가우시안에 semantic segmentation feature를 확률적으로 할당하는 방법을
              소개한다.
            </p>
            <p>
              공간상 $n$번째 가우시안을 $x_n$으로 표기하고 그 가우시안의 class vector를 $\theta_n$이라 하자.
              $\theta_n$은 크기가 클래스의 총 개수이고 0부터 1 사이의 값으로 그 클래스에 속할 확률을 나타낸다. 우리가
              구하고자 하는 것은 가우시안 $x_n$과 모든 픽셀들의 집합 $\mathcal{D}$가 주어졌을 때의 $\theta_n$의 확률분포
              $p(\theta_n \mid x_n, \mathcal{D})$이다.
            </p>
            <p>그런데 이 확률분포를 직접 구하기 어렵기 때문에 Bayes' rule을 써서 아래와 같이 표현한다.</p>
            <p class="math-center">
              $p(\theta_n \mid x_n, \mathcal{D}) = p(y_i \mid \theta_n, x_n, \mathcal{D}) \cdot p(\theta_n)$
            </p>
            <p>이 과정을 Bayesian Update라고도 한다.</p>
            <p>
              먼저 첫 번째 항을 구하는 방법을 살펴보면, 우선 off-the-shelf pixel-wise 2D segmentation 모델을 이용해
              pixel-wise class를 얻고, 이를 one-hot vector로 표현한다. 픽셀 $x_i$에 대한 one-hot vector를 $y_i$라 하자.
            </p>
            <p>
              수식 유도를 위한 중간 변수로 2D 픽셀 $x_i$에 대해 렌더링된 class vector를 $\theta_i$라 하자. $\theta_i$
              또한 크기가 클래스의 총 개수이고 0부터 1 사이의 값으로 $x_i$가 그 클래스에 속할 확률을 나타낸다.
            </p>
            <p>그렇다면 $\theta_i$가 실제 클래스 $y_i$를 맞출 확률은 아래와 같다.</p>
            <p class="math-center">$p(y_i \mid \theta_i) = \prod\limits_{c=1}^{C} (\theta_i^c)^{y_i^c}$</p>
            <p>
              $y_i$가 one-hot vector이므로 우변의 곱은 결국 정답 클래스에 해당하는 $\theta_i$의 element가 된다. 예를
              들어 $y_i = [0, 1, 0]^T$이고 $\theta_i = [0.1, 0.7, 0.2]^T$라면 $p(y_i \mid \theta_i) = 0.7$이 된다.
            </p>
            <p>
              그렇다면 이를 확장해서 $n$번째 가우시안의 class vector $\theta_n$이 실제 클래스 $y_i$를 맞출 확률을 $p(y_i
              \mid \theta_n, x_i, x_n)$으로 표시할 수 있다. $p(y_i \mid \theta_n, x_i, x_n)$와 $p(y_i \mid \theta_i)$
              사이의 관계는 아래의 수식으로 표현할 수 있다.
            </p>
            <p class="math-center">$p(y_i \mid \theta_n, x_i, x_n) \propto p(y_i \mid \theta_i)^{\kappa(x_i, x_n)}$</p>
            <p>
              즉, $n$번째 가우시안이 $i$번째 픽셀 $x'_i$에 미치는 영향 $\kappa(x'_i, x'_n)$을 연결고리로 이용하는
              것이다. 그런데 $\kappa(x'_i, x'_n)$가 줄어들수록 $p(y_i \mid \theta_i)^{\kappa(x_i, x_n)}$가 증가한다는
              점에서 수식에 오류가 있어 보인다. 논문에서는 이 과정이 커널 함수 $\kappa(x'_i, x'_n)$를 이용해 가우시안
              class vector의 확률분포를 조정한다는 점에서 Bayesian Kernel Inference (BKI)에 해당한다고 한다.
            </p>
            <p>
              이제 $\theta_n$에 대한 prior distribution $p(\theta_n)$을 설정해 보자. 논문에서는 아래와 같이 categorical
              distribution의 conjugate prior인 Dirichlet distribution을 이용한다. Dirichlet distribution은 categorical
              distribution의 각 클래스에 속할 확률값 자체를 랜덤변수 $\alpha$로 모델링하여 기존 분포의 신뢰도를 조절하는
              분포이다.
            </p>
            <p class="math-center">$p(\theta_n) \propto \prod\limits_{i=1}^{C} \theta_{n,c}^{\alpha_n^c - 1}$</p>
            <p>
              이제 Bayesian Update를 적용할 수 있다. 우리가 최종적으로 구하고자 하는 값 $p(\theta_n \mid x_n,
              \mathcal{D})$는 아래와 같이 쓸 수 있다.
            </p>
            <p class="math-center">
              $p(\theta_n \mid x_n, \mathcal{D}) \propto \left[ \prod\limits_{i=1}^{N} \left[ \prod\limits_{c=1}^{C}
              (\theta_n^c)^{y_i^c} \right]^{\kappa(x_n, x_i)} \right] \prod\limits_{c=1}^{C} \theta_{n,c}^{\alpha_n^c -
              1}$
            </p>
            <p>
              이때 $p(y_i \mid \theta_n, x_n, \mathcal{D})$ 부분을 구하기 위해 $\mathcal{D}$를 각 픽셀로 분해하여
              $\prod\limits_{i=1}^{N}$로 계산하고 있는 것을 볼 수 있다.
            </p>
            <p>
              이를 조금 더 간단히 하면 아래와 같이 단순히 Dirichlet distribution의 concentration parameter $\alpha$를
              업데이트 하는 것으로도 볼 수 있다.
            </p>
            <p class="math-center">$\alpha_n^c \leftarrow \alpha_n^c + \sum\limits_{i=1}^{N} \kappa(x_i, x_n) y_i^c$</p>
            <p>
              따라서, 결론적으로 코드 상에서 수행하는 것은 위의 식이다. 직관적으로 요약하면 먼저 각 픽셀에 대한 특정
              가우시안 $x_n$의 influence $\kappa(x'_i, x'_n)$를 one-hot vector $y_i$와 곱한다. 이를 $x_n$이 영향을 주는
              모든 픽셀에 대해 수행하여 합한 뒤 그 가우시안의 concentration parameter $\alpha$에 더하면 된다.
            </p>
            <p>
              이러한 방식으로 뉴럴 네트워크를 추가로 사용하지 않고 확률적으로 각 가우시안에 semantic 정보를 할당할 수
              있다.
            </p>
            <p>$\theta_{n}$의 평균과 분산은 아래의 수식을 통해 구할 수 있다.</p>
            <p class="math-center">
              $\mathbb{E}[\theta_n^c] = \cfrac{\alpha_n^c}{\sum\limits_{j=1}^{C} \alpha_n^j}, \quad
              \text{Var}[\theta_n^c] = \cfrac{\mathbb{E}[\theta_n^c] (1 - \mathbb{E}[\theta_n^c])}{1 +
              \sum\limits_{j=1}^{C} \alpha_n^j}$
            </p>

            <h3>Probabilistic Semantic Rasterization</h3>
            <p>
              각 가우시안의 class vector $\theta_n$를 각 픽셀의 class vector $\theta_i$로 렌더링할 때는 색깔을 렌더링할
              때와 같은 수식을 사용한다.
            </p>
            <p class="math-center">$\theta_i = \sum\limits_{n=1}^{N} \kappa(x_i, x_n) \theta_n$</p>
            <p>
              또한 $\theta_n$을 이용하여 $\theta_i$의 expectation과 variance를 계산할 수 있는데, 이는 이후 semantic
              uncertainty를 계산하는 데 사용된다.
            </p>
            <p class="math-center">
              $\mathbb{E}(\theta_i) = \sum\limits_{n=1}^{N} \kappa(x_i, x_n) \mathbb{E}(\theta_n)$
            </p>
            <p>Variance는 각 가우시안들 간의 독립을 가정하고 아래와 같이 모델링한다.</p>
            <p class="math-center">$Var(\theta_i) = \sum\limits_{n=1}^{N} \kappa(x_i, x_n)^2 Var(\theta_n)$</p>
            <p>
              3DGS를 렌더링할 때는 배경의 색깔까지 고려하게 되는데, ray가 모든 가우시안을 통과했을 때 누적된 opacity가
              최종적으로 1이 되어야 하기 때문이다. CSS에서도 마찬가지로 배경의 class를 고려해야 한다. 배경 클래스가 현재
              픽셀 $x_i$에 미치는 영향은 아래의 식과 같다.
            </p>
            <p class="math-center">$\kappa(x_i, x_b) = 1 - \sum\limits_{n=1}^{N} \kappa(x_i, x_n)$</p>
            <p>
              배경의 class vector $\theta_b$ 또한 Dirichlet distribution을 따르며, 각 카테고리의 확률값은 모두 동일하게
              설정한다.
            </p>

            <h3>Uncertainty at Image Level</h3>
            <p>
              픽셀 단위로 uncertainty를 구할 수도 있지만, 이미지 전체의 uncertainty를 정량적으로 구하는 방법도 소개한다.
              각 픽셀의 variance 또는 expectation 값을 이용하여 아래와 같이 구할 수 있다.
            </p>
            <p class="math-center">
              $U(\mathcal{I}_{Var}) = \left| \sum \mathcal{I} \right|^{\cfrac{1}{n}} = \exp \left( \cfrac{1}{n}
              \sum\limits_{i=1}^{n} \log \left( \text{Var}(\hat{\theta}_i) \right) \right)$
            </p>
            <p>
              분산을 이용하여 uncertainty $U(\mathcal{I}_{Var})$를 구하는 식은 위와 같다. $\text{Var}(\hat{\theta}_i)$는
              $\text{Var}({\theta}_i)$의 element 중 정답 카테고리에 해당하는 분산 값을 의미한다.
            </p>
            <p class="math-center">
              $U(\mathcal{I}_\mathbb{E}) = 1 - \cfrac{\sum\limits_{i=1}^{n} \mathbb{E}(\hat{\theta}_i)}{n}$
            </p>
            <p>
              기댓값을 이용하여 uncertainty $U(\mathcal{I}_\mathbb{E})$를 구하는 식은 위와 같다. 마찬가지로
              $\mathbb{E}(\hat{\theta}_i)$는 $\mathbb{E}({\theta}_i)$의 element 중 정답 카테고리에 해당하는 기댓값을
              의미한다. 즉, 정답 카테고리에 할당된 확률이 높을수록 이미지의 uncertainty가 낮아지도록 정의된다.
            </p>
          </div>

          <post-footer></post-footer>
        </section>
      </div>
    </main>

    <footer>
      <p>&copy; 2025 Seongmin Jung<br />Designed and developed by Seongmin Jung</p>
    </footer>
  </body>
</html>
