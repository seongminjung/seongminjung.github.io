                In my undergraduate thesis, I led the software development of an agile autonomous navigation system
                based on scene understanding, without relying on traditional Simultaneous Localization and Mapping
                (SLAM). Our approach combined local path planning with path integration, allowing navigation toward the
                goal while avoiding obstacles. As a testing robot, we mounted a 2D LiDAR on a remote-controlled model
                car. I created an algorithm for line detection and obstacle clustering from the laser scan. This simple
                scene understanding facilitated the computation of optimal paths with reduced computational demands. I
                also elaborated a path integration algorithm by adopting an equation correlating the car's steering
                angle with the rotation radius. As a result, our robot reached an impressive average speed of 2m/s,
                while SLAM-based methods could move only a few centimeters per second in the same condition.
